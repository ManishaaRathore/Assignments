{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a>1. Explain One-Hot Encoding. </a>\n",
    "\n",
    "* One hot encoding is a process to convert data to prepare it for an algorithm and get a better prediction. \n",
    "* With one-hot, we convert each categorical value into a new categorical column and assign a binary value of 1 or 0 to those columns. \n",
    "* Each integer value is represented as a binary vector. \n",
    "* All the values are zero, and the index is marked with a 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a>2. Explain Bag of Words</a>\n",
    "\n",
    "* The bag of words (BOW) model is a representation that turns arbitrary text into fixed length vectors by counting how many times each word\n",
    "appears.\n",
    "* Bag of Words is a text feature engineering technique which converts text into numerical form for model building.\n",
    "* It is applied to the text after all the preprocessing i.e after removing all the unwanted text from the data like punctuations , stops words etc.\n",
    "* Technique we use for implementing Bag of Words is Count  Vecotrizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a>3. Explain Bag of N-Grams</a>\n",
    "* An N-gram is a collection of n successive words. \n",
    "* A Bag of N-Grams model records the number of times that each n-gram appears in each document of a collection.\n",
    "* Bag of N-Grams does not split text into words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a>4. Explain TF-IDF</a>\n",
    "\n",
    "* TF-IDF stands for Term Frequency Inverse Document Frequency .\n",
    "* This is a technique to quantify a word in documents, we generally compute a weight to each word which signifies the importance of the word in the document ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a>5. What is OOV problem?</a>\n",
    "\n",
    "Out-of-vocabulary (OOV) are terms that are not part of the normal lexicon found in a natural language processing environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a>6. What are word embeddings?</a>\n",
    "\n",
    "Word embeddings are basically a form of word representation which give us a way to use an efficient, dense representation in which similar words have a similar encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a>7. Explain Continuous bag of words (CBOW)</a>\n",
    "\n",
    "* CBOW predicts the probability of a word to occur given the words surrounding it.\n",
    "* At first we convert all words into one hot encoding and then predict the target word using thesurrounded words.\n",
    "* It is not necessary to use all the words for prediction , the number of words used for prediction is called window size ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a>8. Explain SkipGram</a>\n",
    "\n",
    "* SkipGram is an algorithm that is used to create word embeddings i.e. high-dimensional vector representation of words.\n",
    "* It is one of the unsupervised learning techniques used to find the most related words for a given word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a>9. Explain Glove Embeddings.</a>\n",
    "\n",
    "* It is an unsupervised learning algorithm aiming to generate word embeddings by aggregating global word co-occurrence matrices from a given corpus.\n",
    "* The resulting embeddings show interesting linear substructures of the word in vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
